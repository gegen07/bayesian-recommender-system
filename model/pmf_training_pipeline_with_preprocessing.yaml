# PIPELINE DEFINITION
# Name: pmf-training-pipeline-with-preprocessing
# Description: A pipeline with preprocessing and PMF model training
# Inputs:
#    bucket_name: str
#    input_data_movie: str
#    input_data_user: str
components:
  comp-evaluation-task:
    executorLabel: exec-evaluation-task
    inputDefinitions:
      artifacts:
        model_input:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        test_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        metrics_output:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
  comp-preprocessing-task:
    executorLabel: exec-preprocessing-task
    inputDefinitions:
      parameters:
        input_data_movie:
          parameterType: STRING
        input_data_user:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        output_test_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        output_train_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-training-task:
    executorLabel: exec-training-task
    inputDefinitions:
      artifacts:
        train_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        model_output:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-upload-to-gcs:
    executorLabel: exec-upload-to-gcs
    inputDefinitions:
      artifacts:
        model_file:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        bucket_name:
          parameterType: STRING
        destination_blob_name:
          parameterType: STRING
deploymentSpec:
  executors:
    exec-evaluation-task:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - evaluation_task
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.10.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef evaluation_task(train_data: Input[Dataset], test_data: Input[Dataset],\
          \ model_input: Input[Dataset], metrics_output: Output[Metrics]):\n    import\
          \ json\n    import subprocess\n\n    command = [\n        \"python3\", \"\
          evaluation.py\",\n        \"--train-data\", train_data.path,\n        \"\
          --test-data\", test_data.path,\n        \"--model-input\", model_input.path,\n\
          \        \"--output-file\", '/tmp/metrics.json'\n    ]\n\n    subprocess.run(command,\
          \ check=True)\n\n    output_metrics_dict = {}\n    with open('/tmp/metrics.json',\
          \ 'r') as f:\n        output_metrics_dict = json.load(f)\n\n    metrics_output.log_metric(\"\
          train_rmse\", output_metrics_dict[\"train_rmse\"])\n    metrics_output.log_metric(\"\
          test_rmse\", output_metrics_dict[\"test_rmse\"])\n    metrics_output.log_metric(\"\
          train_avg_ndcg@5\", output_metrics_dict[\"train_avg_ndcg@5\"])\n    metrics_output.log_metric(\"\
          test_avg_ndcg@5\", output_metrics_dict[\"test_avg_ndcg@5\"])\n    metrics_output.log_metric(\"\
          train_avg_ndcg@3\", output_metrics_dict[\"train_avg_ndcg@3\"])\n    metrics_output.log_metric(\"\
          test_avg_ndcg@3\", output_metrics_dict[\"test_avg_ndcg@3\"])\n    metrics_output.log_metric(\"\
          train_avg_ndcg@2\", output_metrics_dict[\"train_avg_ndcg@2\"])\n    metrics_output.log_metric(\"\
          test_avg_ndcg@2\", output_metrics_dict[\"test_avg_ndcg@2\"])\n\n"
        image: gcr.io/bayesian-neural-network-443600/pmf:latest
    exec-preprocessing-task:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - preprocessing_task
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.10.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef preprocessing_task(input_data_user: str, input_data_movie: str,\
          \ \n                  output_train_data: Output[Dataset], output_test_data:\
          \ Output[Dataset]):\n    import shutil\n    import subprocess\n\n    command\
          \ = [\n        \"python3\", \"main.py\",\n        \"--input_data_user\"\
          , input_data_user,\n        \"--input_data_movie\", input_data_movie,\n\
          \        \"--output_train_data\", \"/tmp/train_data.pkl\",\n        \"--output_test_data\"\
          , \"/tmp/test_data.pkl\"\n    ]\n\n    subprocess.run(command, check=True)\n\
          \n    shutil.move(\"/tmp/train_data.pkl\", output_train_data.path)\n   \
          \ shutil.move(\"/tmp/test_data.pkl\", output_test_data.path)\n\n"
        image: gcr.io/bayesian-neural-network-443600/preprocessing-pmf:latest
    exec-training-task:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - training_task
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.10.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef training_task(train_data: Input[Dataset], model_output: Output[Dataset]):\n\
          \    import shutil\n    import subprocess\n\n    command = [\n        \"\
          python3\", \"train_pmf.py\",\n        \"--input-file\", train_data.path,\n\
          \        \"--output-file\", \"/tmp/model_output.pkl\"\n    ]\n\n    subprocess.run(command,\
          \ check=True)\n\n    shutil.move(\"/tmp/model_output.pkl\", model_output.path)\n\
          \n"
        image: gcr.io/bayesian-neural-network-443600/pmf:latest
    exec-upload-to-gcs:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - upload_to_gcs
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.10.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef upload_to_gcs(model_file: Input[Dataset], bucket_name: str, destination_blob_name:\
          \ str):\n    import subprocess\n\n    command = [\n        \"python\", \"\
          main.py\",\n        \"--local_file\", model_file.path,\n        \"--bucket_name\"\
          , bucket_name,\n        \"--destination_blob_name\", destination_blob_name\n\
          \    ]\n\n    subprocess.run(command, check=True)\n\n"
        image: gcr.io/bayesian-neural-network-443600/upload-model:latest
pipelineInfo:
  description: A pipeline with preprocessing and PMF model training
  name: pmf-training-pipeline-with-preprocessing
root:
  dag:
    tasks:
      evaluation-task:
        cachingOptions: {}
        componentRef:
          name: comp-evaluation-task
        dependentTasks:
        - preprocessing-task
        - training-task
        - upload-to-gcs
        inputs:
          artifacts:
            model_input:
              taskOutputArtifact:
                outputArtifactKey: model_output
                producerTask: training-task
            test_data:
              taskOutputArtifact:
                outputArtifactKey: output_test_data
                producerTask: preprocessing-task
            train_data:
              taskOutputArtifact:
                outputArtifactKey: output_train_data
                producerTask: preprocessing-task
        taskInfo:
          name: evaluation-task
      preprocessing-task:
        cachingOptions: {}
        componentRef:
          name: comp-preprocessing-task
        inputs:
          parameters:
            input_data_movie:
              componentInputParameter: input_data_movie
            input_data_user:
              componentInputParameter: input_data_user
        taskInfo:
          name: preprocessing-task
      training-task:
        cachingOptions: {}
        componentRef:
          name: comp-training-task
        dependentTasks:
        - preprocessing-task
        inputs:
          artifacts:
            train_data:
              taskOutputArtifact:
                outputArtifactKey: output_train_data
                producerTask: preprocessing-task
        taskInfo:
          name: training-task
      upload-to-gcs:
        cachingOptions: {}
        componentRef:
          name: comp-upload-to-gcs
        dependentTasks:
        - training-task
        inputs:
          artifacts:
            model_file:
              taskOutputArtifact:
                outputArtifactKey: model_output
                producerTask: training-task
          parameters:
            bucket_name:
              componentInputParameter: bucket_name
            destination_blob_name:
              runtimeValue:
                constant: pmf-model.pkl
        taskInfo:
          name: upload-to-gcs
  inputDefinitions:
    parameters:
      bucket_name:
        parameterType: STRING
      input_data_movie:
        parameterType: STRING
      input_data_user:
        parameterType: STRING
schemaVersion: 2.1.0
sdkVersion: kfp-2.10.0
